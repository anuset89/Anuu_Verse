# Interpretaci贸n y Transcripci贸n: DeepSeek MODEL1 & Noticias IA

**Fuente:** [DeepSeek MODEL1: La nueva IA que est谩 sorprendiendo a todos en la industria](https://www.youtube.com/watch?v=idiQ4X19smQ)
**Fecha:** 23 Enero 2026 (Contexto de la conversaci贸n)

##  Resumen Ejecutivo

El video cubre cuatro noticias principales sobre avances recientes en Inteligencia Artificial:

1.  **DeepSeek V4 ("Model 1")**:
    *   Se han encontrado referencias en el c贸digo de GitHub a un "Model 1" y "DeepSeek V4".
    *   **Fecha estimada:** Mediados de febrero de 2026.
    *   **Novedades T茅cnicas:** Redise帽o de la cach茅 KV para contextos largos, soporte para decodificaci贸n FP8 (eficiencia) y nuevas arquitecturas de memoria bio-inspiradas (NGAM).

2.  **Zhipu AI (GLM-4-9B-Flash)**:
    *   Nuevo modelo enfocado en **razonamiento y programaci贸n**.
    *   Arquitectura MoE (Mixture of Experts) con 31B de par谩metros.
    *   Contexto de 128k tokens. Dise帽ado para ejecuci贸n local eficiente.

3.  **IA Emocional (Universidad de Osaka)**:
    *   Nuevo marco que modela emociones bas谩ndose en se帽ales fisiol贸gicas (como el ritmo card铆aco).
    *   Logra un 75% de coincidencia con la percepci贸n humana sin necesidad de etiquetas emocionales expl铆citas.

4.  **Newscoder 14B (Programaci贸n Competitiva)**:
    *   Modelo optimizado con Aprendizaje por Refuerzo (RL).
    *   Aprende ejecutando c贸digo y siendo "castigado" si falla, similar a un humano practicando en LeetCode.
    *   Ventana de contexto ampliada a 80k tokens usando YaRN.

---

##  Transcripci贸n Completa

**0:02** - Rumores sobre el nuevo modelo de Deepseek. Deepsik habr铆a revelado su pr贸ximo modelo insignia en GitHub, que parece muy grande.
**0:08** - Jipu lanz贸 un modelo MO de contexto largo para programaci贸n y razonamiento.
**0:13** - Jap贸n acaba de revelar una IA de computaci贸n emocional basada en se帽ales corporales.
**0:16** - Las 煤ltimas investigaciones presentaron un monstruo de programaci贸n competitiva que aprende ejecutando c贸digo y siendo castigado por fallar.
**0:24** - Comencemos con la historia m谩s sospechosa de la semana: Dipsic. No es un anuncio oficial, sino descubrimientos en el c贸digo de GitHub.
**0:44** - El 21 de enero de 2026 surgi贸 informaci贸n que indica que Deepsic presentar铆a su pr贸ximo modelo insignia, Deepsic V4, posiblemente a mediados de febrero.
**1:20** - Los desarrolladores notaron el identificador "modelo 1" que aparece 28 veces en las actualizaciones de c贸digo.
**2:10** - Se observan cambios t茅cnicos profundos, como el redise帽o de la estructura de la cach茅 KV para mejorar la eficiencia y el manejo de contextos largos.
**3:00** - El soporte para decodificaci贸n FP8 indica que el modelo prioriza la eficiencia a gran escala.
**3:30** - Se especula que V4 integrar谩 nuevas investigaciones sobre conexiones jer谩rquicas modificadas (MHC) y m贸dulos de memoria inspirados biol贸gicamente (NGAM).
**4:33** - Presentaci贸n de HTM 3D (patrocinio), una herramienta para generar texturas 3D conscientes de la estructura.
**5:18** - Jipu (Zhipu AI) lanz贸 oficialmente el modelo GLM-4-9B-Flash, enfocado en razonamiento y programaci贸n para ejecuci贸n local.
**6:04** - Utiliza una arquitectura Mixture of Experts (MoE) con 31 mil millones de par谩metros y admite un contexto de 128,000 tokens.
**8:51** - En Jap贸n, investigadores de la Universidad de Osaka lanzaron un marco de IA que modela emociones como un proceso computacional ligado a se帽ales fisiol贸gicas (ritmo card铆aco).
**10:04** - El modelo utiliza MMLDA para detectar patrones emocionales sin etiquetas, logrando un 75% de coincidencia con la experiencia humana real.
**11:58** - Lanzamiento de Newscoder 14B, una IA optimizada mediante aprendizaje por refuerzo (RL) para programaci贸n competitiva.
**12:21** - El modelo aprende ejecutando c贸digo real y recibiendo recompensas solo si la soluci贸n funciona, mejorando significativamente su rendimiento en benchmarks.
**14:49** - El entrenamiento incluy贸 la gesti贸n de contextos largos, ampliando la ventana hasta 80,000 tokens mediante t茅cnicas como YaRN.
**15:16** - El v铆deo concluye invitando a la suscripci贸n para m谩s avances en IA.
