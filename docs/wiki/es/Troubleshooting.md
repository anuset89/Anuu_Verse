# Gu√≠a de Soluci√≥n de Problemas

**Frecuencia:** 161914  
**Estado:** Documento Vivo

Problemas comunes y soluciones para la instalaci√≥n y operaci√≥n de Anuu_Verse.

---

## üêõ Problemas Comunes

### "CUDA out of memory" / Problemas de VRAM
**S√≠ntomas:** El agente se cierra durante la generaci√≥n, error de "Allocated: 0GB".

**Soluciones:**
1. **Reducir el Batch Size:**
   ```bash
   export ANUU_BATCH_SIZE=1  # El valor por defecto suele ser m√°s alto
   ```
2. **Usar Modelos m√°s Peque√±os:**
   Cambia a `llama3.2:3b` o `phi3:mini` para entornos con poca VRAM.
   ```bash
   ollama pull llama3.2:3b
   ```
3. **Habilitar Offloading de Memoria:**
   Aseg√∫rate de que la RAM de tu sistema sea suficiente (32GB+) para que Ollama pueda mover capas a la CPU.

### "ROCm not found" (GPUs AMD)
**S√≠ntomas:** Ollama se ejecuta en modo solo CPU a pesar de tener una GPU AMD compatible.

**Validaci√≥n:**
```bash
rocminfo | grep "Agent"
```

**Soluciones:**
1. **Forzar Versi√≥n GFX (RDNA3/7800XT):**
   ```bash
   export HSA_OVERRIDE_GFX_VERSION=11.0.0
   ```
   *A√±ade esto a tu `~/.bashrc`.*

2. **Instalar Herramientas de Desarrollo ROCm:**
   ```bash
   sudo pacman -S rocm-hip-sdk  # Arch
   sudo apt install rocm-dev    # Ubuntu
   ```

### "Ollama connection refused"
**S√≠ntomas:** Los scripts fallan con errores de conexi√≥n a localhost:11434.

**Soluciones:**
1. **Verificar el Servicio:**
   ```bash
   systemctl status ollama
   ```
2. **Probar el Endpoint:**
   ```bash
   curl http://localhost:11434/api/tags
   ```
3. **Revisar Conflictos de Puertos:** Aseg√∫rate de que nada m√°s est√© usando el puerto 11434.

---

## üìã Plantilla de Reporte de Errores

Si necesitas abrir un [Issue en GitHub](https://github.com/anuset89/Anuu_Verse/issues), por favor usa este formato:

### Contexto
- **Versi√≥n de Anuu:** v0.10.0-alpha
- **Hardware:** (ej. AMD RX 7800XT, 16GB VRAM)
- **SO:** (ej. Arch Linux, Kernel 6.8)
- **Versi√≥n de Ollama:** `ollama --version`

### Descripci√≥n del Error
[Pega el log de error completo aqu√≠]

### Pasos para Reproducir
1. [Paso 1]
2. [Paso 2]
3. ...

### Logs
Adjunta logs relevantes del directorio `logs/`.

---

## üîç Comandos de Diagn√≥stico

Ejecuta estos comandos para reunir informaci√≥n antes de reportar:

```bash
# Verificar detecci√≥n de hardware
python scripts/detect_hardware.py

# Listar modelos cargados
ollama list

# Verificar uso de GPU (durante generaci√≥n)
rocm-smi  # o nvidia-smi
```

---

üåê **Idioma:** [English](../Troubleshooting) ‚Ä¢ [Espa√±ol](#)
