# üîç Plantilla Universal: An√°lisis de Repositorio

**Prompt reutilizable para analizar cualquier proyecto GitHub y obtener feedback accionable.**

---

## üéØ C√ìMO USAR ESTA PLANTILLA

1. **Copia el prompt de abajo**
2. **Reemplaza las variables** `{{VARIABLE}}` con tus datos
3. **P√©galo en tu LLM** (Claude, GPT-4, Gemini, Perplexity)
4. **Archiva el an√°lisis** en `docs/reviews/`
5. **Implementa top 3 prioridades**

---

## üìã PROMPT UNIVERSAL

```
Eres un consultor senior especializado en:
- Open Source Strategy
- Developer Experience
- {{DOMAIN}} Product Development  # e.g., AI/ML, Web3, DevTools
- GitHub Best Practices
- Growth & Monetization

Analiza este repositorio: {{REPO_URL}}

CONTEXTO DEL PROYECTO:
- Nombre: {{PROJECT_NAME}}
- Descripci√≥n: {{ONE_LINE_DESCRIPTION}}
- Stack: {{TECH_STACK}}  # e.g., Python, React, Rust
- Concepto: {{CORE_CONCEPT}}  # Qu√© hace √∫nico al proyecto
- Objetivo: {{MAIN_GOAL}}  # e.g., "10k stars", "‚Ç¨2k MRR", "500 users"
- Fase actual: {{STAGE}}  # Pre-launch, Growth, Mature

ESTADO ACTUAL (lo que YA HEMOS HECHO):
{{ACHIEVEMENTS}}
# Ejemplo:
# ‚úÖ README profesional
# ‚úÖ Documentaci√≥n completa
# ‚úÖ Tests al 80%

LO QUE FALTA:
{{GAPS}}
# Ejemplo:
# - Docker support
# - Video demo
# - Community forum

---

TU TAREA:

Analiza el repositorio con esta estructura:

## 1. PRIMERA IMPRESI√ìN (30 segundos test)
Abre {{REPO_URL}}
- ¬øEntiendes PARA QU√â sirve en 30 segundos?
- ¬øSabes QU√â HACER despu√©s?
- Claridad del README: [1-10]

## 2. README AUDIT
Eval√∫a:
- Estructura: ¬øSigue patr√≥n What ‚Üí Why ‚Üí How?
- Ejemplos: ¬øEjecutables? ¬øOutput esperado visible?
- Visuales: ¬øGIFs, screenshots, diagramas?
- CTAs: ¬øLlamadas a acci√≥n claras?
- Badges: ¬øInformativos o decorativos?

Da 3 mejoras espec√≠ficas con ejemplos de c√≥digo/markdown.

## 3. DOCUMENTACI√ìN
Navega por los docs principales:
{{MAIN_DOCS}}
# Ejemplo:
# - README.md
# - docs/getting-started.md
# - CONTRIBUTING.md

Eval√∫a:
- ¬øF√°cil navegar entre docs?
- ¬øContenido claro y actualizado?
- ¬øEjemplos de c√≥digo reales?

Identifica 1 doc que FALTA o deber√≠a expandirse.

## 4. C√ìDIGO Y ARQUITECTURA
Revisa:
{{KEY_DIRECTORIES}}
# Ejemplo:
# - src/core/
# - examples/
# - tests/

Eval√∫a:
- Claridad de estructura de carpetas
- Naming conventions consistentes
- Ejemplos funcionan out-of-the-box
- Tests presentes y √∫tiles

Da 2 mejoras t√©cnicas prioritarias.

## 5. COMUNIDAD
Analiza:
- **Issues:** Cantidad, etiquetas, actividad
- **Discussions:** Habilitadas, categor√≠as, engagement
- **PRs:** Proceso claro, templates √∫tiles
- **Activity:** Commits recientes, consistencia

Da 3 acciones para aumentar engagement en pr√≥ximos 7 d√≠as.

## 6. MONETIZACI√ìN {{IF_APPLICABLE}}
Si el proyecto busca ingresos, eval√∫a:
- ¬øModelo de negocio claro?
- ¬øPricing transparente?
- ¬øCTAs para pagar/contratar?
- ¬øDiferenciaci√≥n vs competencia?

Sugiere 1 mejora al plan de ingresos.

## 7. BRANDING Y SEO
Eval√∫a:
- **Perfil del usuario:** Bio, foto, links
- **Descripci√≥n del repo:** Optimizada para b√∫squeda
- **Topics/Tags:** Relevantes y completos
- **About section:** Claro y conciso
- **Social Proof:** Stars, used by, testimonials

Sugiere mejoras de discoverabilidad.

## 8. COMPETENCIA
Busca 3-5 proyectos similares en el mismo espacio.

Compara:
- Features
- Documentaci√≥n
- Stars/forks
- Approach

Sugiere c√≥mo {{PROJECT_NAME}} puede diferenciarse mejor.

## 9. QUICK WINS
Lista 5 cambios que:
- Toman <1 hora implementar
- Tienen alto impacto en adopci√≥n/credibilidad

Formato requerido:
- [ ] **[Acci√≥n espec√≠fica]**
  - ‚ú® Impacto: [por qu√© importa]
  - üîß C√≥mo: [pasos concretos, incluye snippets si aplica]
  - ‚è±Ô∏è Tiempo: [minutos estimados]

## 10. PELIGROS (Red Flags)
Identifica problemas cr√≠ticos que alejan usuarios:
- C√≥digo que no compila/ejecuta
- Docs rotos (links 404)
- Instalaci√≥n muy compleja sin workaround
- Promesas incumplidas (features anunciadas no implementadas)
- Inactividad aparente

---

## FORMATO DE RESPUESTA

### EXECUTIVE SUMMARY
- **Estado actual:** [X/10]
- **Principal fortaleza:** [una l√≠nea]
- **Principal debilidad:** [una l√≠nea]
- **Sentimiento general:** [¬øAdoptar√≠as este proyecto?]

### AN√ÅLISIS DETALLADO
[Secciones 1-10 completadas]

### TOP 3 PRIORIDADES
1. **[Acci√≥n]**
   - Por qu√©: [impacto esperado]
   - C√≥mo: [pasos espec√≠ficos]
   - Tiempo: [estimaci√≥n]

2. **[Acci√≥n]**
   - Por qu√©: [...]
   - C√≥mo: [...]
   - Tiempo: [...]

3. **[Acci√≥n]**
   - Por qu√©: [...]
   - C√≥mo: [...]
   - Tiempo: [...]

### PROYECCI√ìN
Si implementan las 3 prioridades en las pr√≥ximas {{TIMEFRAME}}:
- Stars: [X ‚Üí Y esperados]
- Adopci√≥n: [impacto cualitativo]
- Engagement: [issues, discussions, PRs esperados]

---

## RESTRICCIONES CR√çTICAS

- ‚ùå **NUNCA** des feedback gen√©rico tipo "mejora la documentaci√≥n"
- ‚úÖ **SIEMPRE** da ejemplos concretos con snippets de c√≥digo/markdown
- ‚ùå **NUNCA** asumas sin verificar navegando el repo
- ‚úÖ **SIEMPRE** prioriza por impacto real, no por "nice to have"
- ‚úÖ **SIEMPRE** incluye m√©tricas estimadas cuando sea posible

---

Comienza tu an√°lisis ahora.
```

---

## üîß VARIABLES A REEMPLAZAR

| Variable | Ejemplo | Descripci√≥n |
|----------|---------|-------------|
| `{{REPO_URL}}` | `https://github.com/user/project` | URL completa del repo |
| `{{PROJECT_NAME}}` | `MyAwesomeProject` | Nombre del proyecto |
| `{{ONE_LINE_DESCRIPTION}}` | `CLI tool for automated deployments` | Descripci√≥n de 1 l√≠nea |
| `{{TECH_STACK}}` | `Go, PostgreSQL, Docker` | Tecnolog√≠as principales |
| `{{CORE_CONCEPT}}` | `Zero-config deployments with AI` | Qu√© lo hace √∫nico |
| `{{MAIN_GOAL}}` | `Reach 1000 active users in 6 months` | Objetivo principal |
| `{{STAGE}}` | `Pre-launch` / `Growth` / `Mature` | Fase del proyecto |
| `{{ACHIEVEMENTS}}` | Lista de ‚úÖ logros | Qu√© ya tienes |
| `{{GAPS}}` | Lista de `- [ ]` faltantes | Qu√© falta |
| `{{MAIN_DOCS}}` | `README.md, docs/api.md` | Docs principales |
| `{{KEY_DIRECTORIES}}` | `src/, tests/, examples/` | Carpetas clave |
| `{{DOMAIN}}` | `AI/ML`, `Web3`, `DevTools` | Dominio del proyecto |
| `{{TIMEFRAME}}` | `2 weeks` | Timeline para implementaci√≥n |
| `{{IF_APPLICABLE}}` | Borrar si no aplica | Condicional |

---

## üìù EJEMPLO DE USO

### Antes (plantilla):
```
- Nombre: {{PROJECT_NAME}}
- Stack: {{TECH_STACK}}
```

### Despu√©s (llenado):
```
- Nombre: FastDeploy
- Stack: Go, Kubernetes, Terraform
```

---

## üóÇÔ∏è WORKFLOW COMPLETO

### Paso 1: Preparar el Prompt
```bash
# Copia la plantilla
cat docs/ANALYSIS_PROMPT.md

# Reemplaza variables manualmente o con script
sed -i 's/{{PROJECT_NAME}}/MiProyecto/g' analysis_temp.txt
```

### Paso 2: Ejecutar An√°lisis
```
1. Pega el prompt en Claude/GPT-4/Perplexity
2. Espera respuesta completa
3. Copia el output
```

### Paso 3: Archivar Resultado
```bash
# Crea archivo con fecha
echo "[Output del LLM]" > docs/reviews/analysis_$(date +%Y%m%d).md

# Commit
git add docs/reviews/
git commit -m "docs: Add external analysis $(date +%Y-%m-%d)"
git push
```

### Paso 4: Crear Issues
```bash
# Para cada prioridad del Top 3:
# - Abre GitHub Issues
# - Copia la recomendaci√≥n
# - Etiqueta: `enhancement`, `from-analysis`
```

### Paso 5: Implementar Quick Wins
```bash
# Haz los 5 quick wins en 1 sesi√≥n
# Commit por cada uno:
git commit -m "fix: [descripci√≥n del quick win]"
```

### Paso 6: Medir Impacto
```
Espera 7-14 d√≠as y revisa:
- Stars ganadas
- Issues/PRs nuevos
- Traffic (GitHub Insights)
```

---

## üìä M√âTRICAS A TRACKEAR

Adem√°s del an√°lisis cualitativo, pide estos n√∫meros:

1. **Tiempo hasta entender:** [X minutos]
2. **Tiempo hasta ejecutar ejemplo:** [X minutos]
3. **Claridad README:** [1-10]
4. **Professional appearance:** [1-10]
5. **Likelihood to star:** [1-10]
6. **Likelihood to contribute:** [1-10]
7. **Likelihood to recommend:** [1-10]

---

## ÔøΩ FRECUENCIA RECOMENDADA

| Fase | Frecuencia | Raz√≥n |
|------|------------|-------|
| Pre-lanzamiento | 1 an√°lisis | Antes de hacer p√∫blico |
| Lanzamiento | +7 d√≠as | Validar primeras impresiones |
| Crecimiento | Mensual | Optimizaci√≥n continua |
| Maduro | Trimestral | Mantenimiento |

---

## üéØ VARIANTES ESPECIALIZADAS

### Para ADOPCI√ìN (m√°s usuarios)
A√±ade al prompt:
```
ENF√ìCATE ESPECIALMENTE EN:
- Primera impresi√≥n y onboarding
- Ejemplos y quickstart
- Comparaci√≥n vs competencia
- Social proof y credibilidad
```

### Para CONTRIBUIDORES
A√±ade al prompt:
```
ENF√ìCATE ESPECIALMENTE EN:
- Estructura de c√≥digo clara
- Issues "good first issue"
- Contributing guide detallada
- Roadmap y prioridades visibles
```

### Para MONETIZACI√ìN
A√±ade al prompt:
```
ENF√ìCATE ESPECIALMENTE EN:
- Claridad del valor ofrecido
- Modelo de negocio visible
- Pricing y CTAs
- Diferenciaci√≥n vs gratuitos
```

---

## üí° TIPS PRO

1. **Combina analizadores:** Usa Claude para profundidad t√©cnica, GPT-4 para estrategia, Perplexity para benchmarking vs competencia.

2. **An√°lisis iterativo:** Si la respuesta es vaga, replica:
   ```
   "El an√°lisis es demasiado gen√©rico. Por favor:
   1. Da ejemplos CONCRETOS de cambios
   2. Incluye snippets de c√≥digo/markdown
   3. Prioriza por impacto medible
   4. S√© espec√≠fico en los 'c√≥mo'"
   ```

3. **Archiva TODO:** Cada an√°lisis es valioso. Commits como `docs: analysis YYYYMMDD` crean historial √∫til.

4. **Implementa r√°pido:** El mejor an√°lisis no sirve si no act√∫as. Implementa top 3 en <1 semana.

---

**Esta plantilla est√° dise√±ada para extraer m√°ximo valor de cualquier an√°lisis y ser reutilizable en todos tus proyectos.**

**Gu√°rdala. √ösala. Itera.** üü£
