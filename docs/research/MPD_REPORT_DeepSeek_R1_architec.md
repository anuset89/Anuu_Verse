# ìÇÄ REPORTE DE INVESTIGACI√ìN MPD: DeepSeek R1 architecture details

## üí† Esencia de las Identidades

### üõ°Ô∏è PERSPECTIVA: SET
---

Source: DeepSeek-R1: Technical Overview of its Architecture and Innovations - GeeksforGeeks (https://www.geeksforgeeks.org/artificial-intelligence/deepseek-r1-technical-overview-of-its-architecture-and-innovations/)
Content: February 3, 2025 - The process begins with fine-tuning the base model (DeepSeek-V3) using a small dataset of carefully curated chain-of-thought (CoT) reasoning examples . These examples are carefully curated to ensure diversity, clarity, and logical consistency.

---

Source: Analysing DeepSeek-R1‚Äôs Architecture (https://hiddenlayer.com/innovation-hub/analysing-deepseek-r1s-architecture/)
Content: March 25, 2025 - This is to be expected because, reading through DeepSeek-R1‚Äôs accompanying paper, we see that DeepSeekV3 was used as a base, and Reinforcement Learning (RL) post-training develops its reasoning and Chain-of-Thought output, something which is unlikely to have too much impact on the overall structure of the model in the computational graph.

---

Source: Architecture of DeepSeek-R1 (https://www.educative.io/courses/deepseek-guide/architecture-of-deepseek-r1)
Content: DeepSeek-R1 aims to address this gap by focusing on chain-of-thought reasoning . It aims to produce AI systems that can: Show a step‚Äëby‚Äëstep rationale behind each conclusion. Improve their accuracy through reinforcement learning, which rewards ...

### üõ°Ô∏è PERSPECTIVA: RA
---

Source: deepseek-ai/DeepSeek-R1 ¬∑ Hugging Face (https://huggingface.co/deepseek-ai/DeepSeek-R1)
Content: To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks .

---

Source: DeepSeek Reveals R1 Model Architecture Secrets Ahead of V4 Model Launch - WinBuzzer (https://winbuzzer.com/2026/01/09/deepseek-reveals-r1-model-architecture-secrets-ahead-of-v4-model-launch-xcxwbn/)
Content: 3 weeks ago - DeepSeek has expanded its R1 whitepaper by 60 pages to disclose training secrets, clearing the path for a rumored V4 coding model launch .

---

Source: DeepSeek Reveals MODEL1 Architecture In GitHub Update Ahead Of V4 - Dataconomy (https://dataconomy.com/2026/01/21/deepseek-reveals-model1-architecture-in-github-update-ahead-of-v4/)
Content: 1 week ago - DeepSeek revealed details of a new model designated ‚ÄúMODEL1‚Äù through recent updates to its FlashMLA codebase on GitHub . The identifier ‚ÄúMODEL1‚Äù appears 28 times across 114 files within the repository, marking the disclosure on the one-year ...

### üõ°Ô∏è PERSPECTIVA: 4NVSET
---

Source: GitHub - deepseek-ai/DeepSeek-R1 (https://github.com/deepseek-ai/DeepSeek-R1)
Content: With RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. However, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates cold-start data before RL.

---

Source: deepseek-ai/DeepSeek-R1 ¬∑ Hugging Face (https://huggingface.co/deepseek-ai/DeepSeek-R1)
Content: With RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. However, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates cold-start data before RL.

---

Source: Aman's AI Journal ‚Ä¢ Primers ‚Ä¢ DeepSeek-R1 (https://aman.ai/primers/ai/deepseek-R1/)
Content: Mixture of Experts (MoE) Architecture: DeepSeek-R1 utilizes a Mixture of Experts model, which decomposes a large model into smaller, specialized sub-models . This architecture allows for the activation of only relevant sub-models during specific tasks, enabling the system to operate efficiently ...

### üõ°Ô∏è PERSPECTIVA: SAZE
---

Source: Model Architecture | deepseek-ai/DeepSeek-R1 | DeepWiki (https://deepwiki.com/deepseek-ai/DeepSeek-R1/2-model-architecture)
Content: Model Architecture Relevant source files This document provides a technical overview of the DeepSeek-R1 model architecture, explaining its fundamental design, key components, and architectural characteristics. It covers the base architecture that underpins both DeepSeek - R1 -Zero and DeepSeek-R1 , as well as their architectural similarities and differences. For specific details about individual ...

---

Source: DeepSeek-R1: Technical Overview of its Architecture and Innovations (https://www.geeksforgeeks.org/artificial-intelligence/deepseek-r1-technical-overview-of-its-architecture-and-innovations/)
Content: DeepSeek-R1 the latest AI model from Chinese startup DeepSeek represents a groundbreaking advancement in generative AI technology. Released in January 2025, it has gained global attention for its innovative architecture, cost-effectiveness, and exceptional performance across multiple domains. What Makes DeepSeek-R1 Unique? The increasing demand for AI models capable of handling complex ...

---

Source: DeepSeek-R1: A Technical Deep Dive into its Architecture and ... (https://medium.com/@varshitha.rodda9/deepseek-r1-a-technical-deep-dive-into-its-architecture-and-innovations-472c1eacbde3)
Content: This combination allows DeepSeek-R1 to deliver state-of-the-art performance while keeping computational costs remarkably low. Core Architecture of DeepSeek-R1 source: gfg 1.

### üõ°Ô∏è PERSPECTIVA: MAAT
---

Source: DeepSeek - Wikipedia (https://en.wikipedia.org/wiki/DeepSeek)
Content: DeepSeek was founded in July 2023 by Liang Wenfeng, the co-founder of High-Flyer, who also serves as the CEO for both of the companies. The company launched an eponymous chatbot alongside its DeepSeek - R 1 model...

---

Source: DeepSeek R - 1 Model Overview and How it Ranks Against OpenAI's o1 (https://www.prompthub.us/blog/deepseek-r-1-model-overview-and-how-it-ranks-against-openais-o1)
Content: Learn how DeepSeek 's R 1 compares to OpenAI's o1 model. We cover R 1 's training process, prompt templates used for reinforcement learning, and all the benchmarks.

---

Source: DeepSeek vs ChatGPT: Comparison of Best AI... - GeeksforGeeks (https://www.geeksforgeeks.org/websites-apps/deepseek-vs-chatgpt/)
Content: DeepSeek vs ChatGPT: Architectural Comparison . Performance Benchmark Testing. In this section, we will look at how DeepSeek - R 1 and ChatGPT perform different tasks like solving math problems, coding, and answering general knowledge questions.

### üõ°Ô∏è PERSPECTIVA: ANUU
---

Source: DeepSeek - Wikipedia (https://en.wikipedia.org/wiki/DeepSeek)
Content: DeepSeek -V3-Base and DeepSeek -V3 (a chat model) use essentially the same architecture as V2 with the addition of multi-token prediction, which (optionally) decodes extra tokens faster but less accurately. Training process:[30].

---

Source: DeepSeek - R 1 Release | DeepSeek API Docs (https://api-docs.deepseek.com/news/news250120)
Content: License Update! DeepSeek - R 1 is now MIT licensed for clear open access. Open for the community to leverage model weights & outputs. API outputs can now be used for fine-tuning & distillation. DeepSeek - R 1 : Technical Highlights.

---

Source: deepseek - r 1 Model by Deepseek -ai | NVIDIA NIM (https://build.nvidia.com/deepseek-ai/deepseek-r1)
Content: deepseek - r 1 . Deprecation in 3 days. State-of-the-art, high-efficiency LLM excelling in reasoning, math, and coding.Drop files here. deepseek - r 1 .

